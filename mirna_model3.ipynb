{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mirna_model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielelbrecht/mirna/blob/master/mirna_model3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6BeQMA6f3lht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, GRU, LSTM, TimeDistributed, Dropout, Dense, Permute, Flatten, Multiply, RepeatVector, Activation, Masking, Bidirectional\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.wrappers import Wrapper\n",
        "from keras.engine.topology import InputSpec\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HS9wM9vy3vH5",
        "colab_type": "code",
        "outputId": "ae7b6892-b7bd-461d-a174-101e30b83d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Load data sets\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "pos_file_obj = drive.CreateFile({'id': '1vl-qE0U5W6ll3JH41QqDajyx6oAwC3C0'})                       \n",
        "pos_file_obj.GetContentFile('input.txt')\n",
        "\n",
        "neg_file_obj = drive.CreateFile({'id': '1Rnh8RHUsmCGmiCZobu3g7ezeUJQq0CH-'})                       \n",
        "neg_file_obj.GetContentFile('negatives.txt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 27.6MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.1MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.0MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.5MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.0MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.4MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.9MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.4MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.3MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.8MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.8MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.0MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.0MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.0MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.0MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.1MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.1MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 45.1MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.0MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.0MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.1MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.0MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.1MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 9.9MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.0MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.0MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.0MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.3MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 55.9MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 56.9MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 59.2MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 54.6MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 53.1MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 61.0MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 61.3MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 61.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 11.5MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 11.4MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 11.4MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 11.4MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 11.4MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 11.5MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 11.6MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 11.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 11.5MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 11.5MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 61.9MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 61.5MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 63.1MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 63.1MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 10.4MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 10.5MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 10.4MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 10.4MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 10.4MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 10.4MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 10.4MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 10.5MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 10.5MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 10.5MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 64.3MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 64.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 51.8MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 52.4MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 53.4MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 54.1MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 54.0MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 54.6MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 55.3MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 55.0MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 55.8MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 57.6MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 75.8MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 76.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 75.5MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 75.3MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 75.0MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 74.0MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 74.6MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 73.8MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 73.4MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 65.6MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 65.9MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 67.3MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 68.4MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 67.5MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 67.6MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 67.9MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 68.0MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 69.4MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 69.2MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 79.0MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 80.2MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 77.0MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 23.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbK21Eqz3yWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_file_obj\n",
        "pos_content = pos_file_obj.GetContentString()\n",
        "neg_content = neg_file_obj.GetContentString()\n",
        "pos_file = []\n",
        "neg_file = []\n",
        "temp = []\n",
        "\n",
        "for x in pos_content:\n",
        "  if x == '\\n':\n",
        "    pos_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "for x in neg_content:\n",
        "  if x == '\\n':\n",
        "    neg_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "    \n",
        "def read_line(line):\n",
        "\n",
        "    array = []\n",
        "\n",
        "    for entry in line:\n",
        "        if entry == '0':\n",
        "            array.append(np.int32(0))\n",
        "        if entry == '1':\n",
        "            array.append(np.int32(1))\n",
        "        if len(array) == 16:\n",
        "          break\n",
        "\n",
        "    return np.asarray(array)\n",
        "  \n",
        "def process_data(pos_file, neg_file):\n",
        "\n",
        "    data = []\n",
        "    is_example = 0\n",
        "    pos_examples = 0\n",
        "    neg_examples = 0\n",
        "\n",
        "    for line in pos_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            pos_examples = pos_examples + 1\n",
        "\n",
        "    for line in neg_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            neg_examples = neg_examples + 1\n",
        "\n",
        "    return np.asarray(data), pos_examples, neg_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Kwf2B_I35Tn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Process the data and generate training labels\n",
        "\n",
        "full_data, num_pos, num_neg = process_data(pos_file, neg_file)\n",
        "\n",
        "# Generate labels\n",
        "pos_labels = np.ones(num_pos)\n",
        "neg_labels = np.zeros(num_neg)\n",
        "data_labels = np.concatenate((pos_labels, neg_labels))\n",
        "\n",
        "binary_labels = np.zeros([len(data_labels), 2])\n",
        "\n",
        "for i in range(len(data_labels)):\n",
        "    if data_labels[i] == 1:\n",
        "        binary_labels[i][1] = 1\n",
        "    else:\n",
        "        binary_labels[i][0] = 1\n",
        "\n",
        "\n",
        "# Get mask length\n",
        "mask_length = 0\n",
        "for i in range(len(full_data)):\n",
        "    if len(full_data[i]) > mask_length:\n",
        "        mask_length = len(full_data[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJ9mekIe38ZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad data\n",
        "data_padded = pad_sequences(full_data, maxlen=mask_length, dtype='object', padding='post', truncating='post', value=0)\n",
        "\n",
        "# Shuffle data and get training and validation sets\n",
        "indices = np.random.permutation(35267)\n",
        "shuffled_data = data_padded[indices]\n",
        "shuffled_labels = binary_labels[indices]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cq6XQao3-1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define hyper parameters\n",
        "LSTM1_units = 32\n",
        "LSTM2_units = 16\n",
        "fully_connected_layer1_units = 32\n",
        "fully_connected_layer2_units = 32\n",
        "output_size = 2\n",
        "learning_rate = 0.01\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOSR3X7q4BNe",
        "colab_type": "code",
        "outputId": "e73cfd69-8e03-4669-eba9-1f33a886de12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "# Functional API model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(mask_length, 16), name='inputs')\n",
        "\n",
        "\n",
        "# LSTM Layers\n",
        "lstm1 = GRU(20, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(inputs)\n",
        "lstm2 = GRU(10, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(lstm1)\n",
        "\n",
        "#Flatten\n",
        "flatten = Flatten()(lstm2)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "do1 = Dropout(0.1)(flatten)\n",
        "fc1 = Dense(200, activation='sigmoid')(do1)\n",
        "do2 = Dropout(0.1)(fc1)\n",
        "fc2 = Dense(100, activation='sigmoid')(do2)\n",
        "\n",
        "# Output layer\n",
        "softmax = Dense(output_size, activation='softmax')(fc2)\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model2 = Model(inputs=inputs, outputs=softmax)\n",
        "\n",
        "model2.compile(optimizer='rmsprop',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 142, 16)           0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 142, 20)           2220      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 142, 10)           930       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1420)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1420)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               284200    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 307,652\n",
            "Trainable params: 307,652\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-OFwAVVrfoh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kfold(k, model, data, labels):\n",
        "  \n",
        "  epochs = 10\n",
        "  length = len(data)\n",
        "  accuracy = 0\n",
        "  model.save_weights('initial_weights')\n",
        "  \n",
        "  for i in range(k):\n",
        "    \n",
        "    model.load_weights('initial_weights')\n",
        "    \n",
        "    #Get validation and training splits from data set\n",
        "    lower_bound = int(i*(length/k))\n",
        "    upper_bound = int((i+1)*(length/k))\n",
        "\n",
        "    train_data = np.concatenate((data[0:lower_bound], data[upper_bound:length]))\n",
        "    val_data = data[lower_bound:upper_bound]\n",
        "    \n",
        "    train_labels = np.concatenate((labels[0:lower_bound], labels[upper_bound:length]))\n",
        "    val_labels = labels[lower_bound:upper_bound]\n",
        "    \n",
        "    history = model.fit(train_data, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,\n",
        "                      batch_size = 128,\n",
        "                      validation_data=(val_data, val_labels))\n",
        "    \n",
        "    accuracy = accuracy + history.history['acc'][epochs-1]\n",
        "    \n",
        "\n",
        "  return accuracy / k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acTEHWmErgSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1819
        },
        "outputId": "045166e9-a4f1-408b-d8e0-918543804905"
      },
      "cell_type": "code",
      "source": [
        "kfold_acc = kfold(5, model2, shuffled_data, shuffled_labels)\n",
        "print('5-vold cross validation accuracy is: ', kfold_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 97s 3ms/step - loss: 0.4495 - acc: 0.7895 - val_loss: 0.3797 - val_acc: 0.8306\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3887 - acc: 0.8248 - val_loss: 0.3644 - val_acc: 0.8358\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3656 - acc: 0.8363 - val_loss: 0.3427 - val_acc: 0.8484\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3545 - acc: 0.8417 - val_loss: 0.3326 - val_acc: 0.8544\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3444 - acc: 0.8469 - val_loss: 0.3201 - val_acc: 0.8591\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 93s 3ms/step - loss: 0.3342 - acc: 0.8530 - val_loss: 0.3131 - val_acc: 0.8642\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3283 - acc: 0.8567 - val_loss: 0.3131 - val_acc: 0.8640\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.3204 - acc: 0.8621 - val_loss: 0.2992 - val_acc: 0.8694\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.3141 - acc: 0.8621 - val_loss: 0.2973 - val_acc: 0.8694\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3113 - acc: 0.8645 - val_loss: 0.3025 - val_acc: 0.8666\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.4663 - acc: 0.7783 - val_loss: 0.4049 - val_acc: 0.8162\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.3886 - acc: 0.8235 - val_loss: 0.3629 - val_acc: 0.8344\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3677 - acc: 0.8343 - val_loss: 0.3376 - val_acc: 0.8503\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3552 - acc: 0.8440 - val_loss: 0.3794 - val_acc: 0.8296\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.3429 - acc: 0.8480 - val_loss: 0.3234 - val_acc: 0.8633\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3347 - acc: 0.8528 - val_loss: 0.3141 - val_acc: 0.8674\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3281 - acc: 0.8551 - val_loss: 0.3063 - val_acc: 0.8673\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3209 - acc: 0.8599 - val_loss: 0.3058 - val_acc: 0.8676\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3159 - acc: 0.8617 - val_loss: 0.2958 - val_acc: 0.8735\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3098 - acc: 0.8653 - val_loss: 0.2930 - val_acc: 0.8747\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.4639 - acc: 0.7823 - val_loss: 0.4085 - val_acc: 0.8079\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 93s 3ms/step - loss: 0.3874 - acc: 0.8220 - val_loss: 0.3603 - val_acc: 0.8374\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 93s 3ms/step - loss: 0.3621 - acc: 0.8376 - val_loss: 0.3404 - val_acc: 0.8528\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3541 - acc: 0.8427 - val_loss: 0.3310 - val_acc: 0.8555\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3432 - acc: 0.8485 - val_loss: 0.3179 - val_acc: 0.8618\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3362 - acc: 0.8531 - val_loss: 0.3105 - val_acc: 0.8649\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.3259 - acc: 0.8578 - val_loss: 0.3279 - val_acc: 0.8609\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.3214 - acc: 0.8585 - val_loss: 0.3100 - val_acc: 0.8622\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 93s 3ms/step - loss: 0.3143 - acc: 0.8618 - val_loss: 0.3018 - val_acc: 0.8740\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3104 - acc: 0.8658 - val_loss: 0.2911 - val_acc: 0.8737\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.4665 - acc: 0.7792 - val_loss: 0.3768 - val_acc: 0.8374\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3871 - acc: 0.8242 - val_loss: 0.3673 - val_acc: 0.8293\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3709 - acc: 0.8316 - val_loss: 0.3414 - val_acc: 0.8497\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3561 - acc: 0.8416 - val_loss: 0.3242 - val_acc: 0.8632\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.3468 - acc: 0.8479 - val_loss: 0.3158 - val_acc: 0.8647\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3350 - acc: 0.8540 - val_loss: 0.3037 - val_acc: 0.8710\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3306 - acc: 0.8547 - val_loss: 0.3035 - val_acc: 0.8711\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 96s 3ms/step - loss: 0.3249 - acc: 0.8561 - val_loss: 0.2936 - val_acc: 0.8776\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 94s 3ms/step - loss: 0.3165 - acc: 0.8623 - val_loss: 0.3007 - val_acc: 0.8706\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 95s 3ms/step - loss: 0.3101 - acc: 0.8656 - val_loss: 0.2844 - val_acc: 0.8791\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.4705 - acc: 0.7751 - val_loss: 0.3840 - val_acc: 0.8255\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3896 - acc: 0.8237 - val_loss: 0.3554 - val_acc: 0.8404\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 98s 3ms/step - loss: 0.3688 - acc: 0.8344 - val_loss: 0.3317 - val_acc: 0.8492\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.3502 - acc: 0.8441 - val_loss: 0.3243 - val_acc: 0.8536\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 93s 3ms/step - loss: 0.3418 - acc: 0.8483 - val_loss: 0.3233 - val_acc: 0.8606\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3362 - acc: 0.8525 - val_loss: 0.3258 - val_acc: 0.8560\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 94s 3ms/step - loss: 0.3281 - acc: 0.8556 - val_loss: 0.3199 - val_acc: 0.8635\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.3198 - acc: 0.8605 - val_loss: 0.3032 - val_acc: 0.8690\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.3147 - acc: 0.8620 - val_loss: 0.3063 - val_acc: 0.8684\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 95s 3ms/step - loss: 0.3095 - acc: 0.8660 - val_loss: 0.2913 - val_acc: 0.8791\n",
            "5-vold cross validation accuracy is:  0.8654407867561268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXWVgtQQrkHb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def perfeval(predictions, Y_test, verbose=0):\n",
        " class_label = np.uint8(np.argmax(predictions,axis=1))\n",
        " R = np.asarray(np.uint8([sublist[1] for sublist in Y_test]))\n",
        " CM = metrics.confusion_matrix(R, class_label, labels=None)\n",
        " \n",
        " CM = np.double(CM)\n",
        " acc = (CM[0][0]+CM[1][1])/(CM[0][0]+CM[0][1]+CM[1][0]+CM[1][1])\n",
        " se = (CM[0][0])/(CM[0][0]+CM[0][1])\n",
        " sp = (CM[1][1])/(CM[1][0]+CM[1][1])\n",
        " f1 = (2*CM[0][0])/(2*CM[0][0]+CM[0][1]+CM[1][0])\n",
        " ppv = (CM[0][0])/(CM[0][0]+CM[1][0])\n",
        " mcc = (CM[0][0]*CM[1][1]-CM[0][1]*CM[1][0])/np.sqrt((CM[0][0]+CM[0][1])*(CM[0][0]+CM[1][0])*(CM[0][1]+CM[1][1])*(CM[1][0]+CM[1][1]))\n",
        " gmean = np.sqrt(se*sp)\n",
        " auroc = metrics.roc_auc_score(Y_test[:,0],predictions[:,0])\n",
        " aupr = metrics.average_precision_score(Y_test[:,0],predictions[:,0],average=\"micro\")\n",
        "  \n",
        " if verbose == 1:\n",
        "  print(\"SE:\",\"{:.3f}\".format(se),\"SP:\",\"{:.3f}\".format(sp),\"F-Score:\",\"{:.3f}\".format(f1), \"PPV:\",\"{:.3f}\".format(ppv),\"gmean:\",\"{:.3f}\".format(gmean),\"AUROC:\",\"{:.3f}\".format(auroc), \"AUPR:\",\"{:.3f}\".format(aupr))\n",
        " \n",
        " return [se,sp,f1,ppv,gmean,auroc,aupr,CM]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SzZdKX5rqyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abf4e4e3-86d1-47fd-d673-863ca24a0f57"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Get advanced metrics\n",
        "preds = model2.predict(shuffled_data[0:5000])\n",
        "met = perfeval(preds, shuffled_labels[0:5000], 1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE: 0.877 SP: 0.905 F-Score: 0.886 PPV: 0.894 gmean: 0.891 AUROC: 0.957 AUPR: 0.956\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}