{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mirna_model2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielelbrecht/mirna/blob/master/mirna_model2_with_schedule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6BeQMA6f3lht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, TimeDistributed, Dropout, Dense, Permute, Flatten, Multiply, RepeatVector, Activation, Masking, Bidirectional\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.wrappers import Wrapper\n",
        "from keras.engine.topology import InputSpec\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HS9wM9vy3vH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fc1f3204-12a6-482c-d1cb-90aa988619d7"
      },
      "cell_type": "code",
      "source": [
        "# Load data sets\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "pos_file_obj = drive.CreateFile({'id': '1vl-qE0U5W6ll3JH41QqDajyx6oAwC3C0'})                       \n",
        "pos_file_obj.GetContentFile('input.txt')\n",
        "\n",
        "neg_file_obj = drive.CreateFile({'id': '1Rnh8RHUsmCGmiCZobu3g7ezeUJQq0CH-'})                       \n",
        "neg_file_obj.GetContentFile('negatives.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 19.7MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.1MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.0MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 7.6MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 7.6MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 7.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 7.7MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 7.7MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 7.7MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 37.8MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 8.6MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 8.7MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 8.8MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 8.7MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 8.7MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 8.5MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 8.6MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 8.6MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 8.6MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 8.8MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 44.4MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 42.2MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 42.7MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 39.9MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 41.0MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 45.9MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 45.1MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 45.2MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 9.9MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 9.9MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 9.9MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 9.9MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 9.9MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 10.1MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 10.0MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 9.9MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 10.0MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 10.0MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 48.0MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 44.8MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 44.9MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 47.0MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 9.0MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 9.0MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 8.9MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 8.9MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 8.9MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 8.9MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 8.8MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 8.9MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 8.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 8.9MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 42.9MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 45.4MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 39.9MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 40.2MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 41.1MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 41.8MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 42.1MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 43.1MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 42.7MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 42.5MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 43.1MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 43.4MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 54.5MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 53.4MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 52.1MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 51.6MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 52.1MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 51.8MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 52.5MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 52.9MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 52.3MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 42.4MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 40.8MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 41.6MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 42.0MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 41.9MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 41.5MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 41.7MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 42.2MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 42.0MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 41.8MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 51.5MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 53.3MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 53.3MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 19.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbK21Eqz3yWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_file_obj\n",
        "pos_content = pos_file_obj.GetContentString()\n",
        "neg_content = neg_file_obj.GetContentString()\n",
        "pos_file = []\n",
        "neg_file = []\n",
        "temp = []\n",
        "\n",
        "for x in pos_content:\n",
        "  if x == '\\n':\n",
        "    pos_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "for x in neg_content:\n",
        "  if x == '\\n':\n",
        "    neg_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "    \n",
        "def read_line(line):\n",
        "\n",
        "    array = []\n",
        "\n",
        "    for entry in line:\n",
        "        if entry == '0':\n",
        "            array.append(np.int32(0))\n",
        "        if entry == '1':\n",
        "            array.append(np.int32(1))\n",
        "        if len(array) == 16:\n",
        "          break\n",
        "\n",
        "    return np.asarray(array)\n",
        "  \n",
        "def process_data(pos_file, neg_file):\n",
        "\n",
        "    data = []\n",
        "    is_example = 0\n",
        "    pos_examples = 0\n",
        "    neg_examples = 0\n",
        "\n",
        "    for line in pos_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            pos_examples = pos_examples + 1\n",
        "\n",
        "    for line in neg_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            neg_examples = neg_examples + 1\n",
        "\n",
        "    return np.asarray(data), pos_examples, neg_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Kwf2B_I35Tn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Process the data and generate training labels\n",
        "\n",
        "full_data, num_pos, num_neg = process_data(pos_file, neg_file)\n",
        "\n",
        "# Generate labels\n",
        "pos_labels = np.ones(num_pos)\n",
        "neg_labels = np.zeros(num_neg)\n",
        "data_labels = np.concatenate((pos_labels, neg_labels))\n",
        "\n",
        "binary_labels = np.zeros([len(data_labels), 2])\n",
        "\n",
        "for i in range(len(data_labels)):\n",
        "    if data_labels[i] == 1:\n",
        "        binary_labels[i][1] = 1\n",
        "    else:\n",
        "        binary_labels[i][0] = 1\n",
        "\n",
        "\n",
        "# Get mask length\n",
        "mask_length = 0\n",
        "for i in range(len(full_data)):\n",
        "    if len(full_data[i]) > mask_length:\n",
        "        mask_length = len(full_data[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJ9mekIe38ZH",
        "colab_type": "code",
        "outputId": "f2e9aa1b-6f85-4616-f71e-90e4b450258c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Pad data\n",
        "data_padded = pad_sequences(full_data, maxlen=mask_length, dtype='object', padding='post', truncating='post', value=0)\n",
        "\n",
        "# Shuffle data and get training and validation sets\n",
        "indices = np.random.permutation(35267)\n",
        "shuffled_data = data_padded[indices]\n",
        "shuffled_labels = binary_labels[indices]\n",
        "\n",
        "print(data_padded.shape)\n",
        "print(shuffled_data.shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35267, 142, 16)\n",
            "(35267, 142, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8cq6XQao3-1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define hyper parameters\n",
        "LSTM1_units = 32\n",
        "LSTM2_units = 16\n",
        "fully_connected_layer1_units = 32\n",
        "fully_connected_layer2_units = 32\n",
        "output_size = 2\n",
        "learning_rate = 0.01\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ImiqpmNcULML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "def schedule_function(epoch, lr):\n",
        "  if epoch==15 or epoch==30:\n",
        "    return lr/10\n",
        "  else:\n",
        "    return lr\n",
        "\n",
        "\n",
        "schedule = LearningRateScheduler(schedule_function, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOSR3X7q4BNe",
        "colab_type": "code",
        "outputId": "7e37d4d9-2e03-46f1-b07a-9df1a0ca3192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "# Functional API model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(mask_length, 16), name='inputs')\n",
        "\n",
        "\n",
        "# LSTM Layers\n",
        "lstm1 = Bidirectional(LSTM(20, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), merge_mode='concat')(inputs)\n",
        "lstm2 = Bidirectional(LSTM(10, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), merge_mode='concat')(lstm1)\n",
        "\n",
        "#Flatten\n",
        "flatten = Flatten()(lstm2)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "do1 = Dropout(0.1)(flatten)\n",
        "fc1 = Dense(100, activation='sigmoid')(do1)\n",
        "do2 = Dropout(0.1)(fc1)\n",
        "fc2 = Dense(100, activation='sigmoid')(do2)\n",
        "\n",
        "# Output layer\n",
        "softmax = Dense(output_size, activation='softmax')(fc2)\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model2 = Model(inputs=inputs, outputs=softmax)\n",
        "\n",
        "model2.compile(optimizer='rmsprop',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 142, 16)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 142, 40)           5920      \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 142, 20)           4080      \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2840)              0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 2840)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               284100    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 304,402\n",
            "Trainable params: 304,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kHwHHSOL6Na-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        },
        "outputId": "9be70e14-e0b9-4773-bfe4-e50dbe818da0"
      },
      "cell_type": "code",
      "source": [
        "# Get train and val data\n",
        "train_data = shuffled_data[0:30000]\n",
        "train_labels = shuffled_labels[0:30000]\n",
        "\n",
        "val_data = shuffled_data[30000:35267]\n",
        "val_labels = shuffled_labels[30000:35267]\n",
        "\n",
        "\n",
        "history = model2.fit(train_data, \n",
        "                    train_labels, \n",
        "                    epochs=40,\n",
        "                    batch_size = 128,\n",
        "                    validation_data=(val_data, val_labels),\n",
        "                    callbacks=[schedule])\n",
        "    \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 5267 samples\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 324s 11ms/step - loss: 0.4276 - acc: 0.8085 - val_loss: 0.3602 - val_acc: 0.8348\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 320s 11ms/step - loss: 0.3666 - acc: 0.8353 - val_loss: 0.3536 - val_acc: 0.8422\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 321s 11ms/step - loss: 0.3505 - acc: 0.8466 - val_loss: 0.3579 - val_acc: 0.8415\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 313s 10ms/step - loss: 0.3394 - acc: 0.8496 - val_loss: 0.3226 - val_acc: 0.8597\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 312s 10ms/step - loss: 0.3265 - acc: 0.8553 - val_loss: 0.3201 - val_acc: 0.8627\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 313s 10ms/step - loss: 0.3226 - acc: 0.8584 - val_loss: 0.3195 - val_acc: 0.8627\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 312s 10ms/step - loss: 0.3150 - acc: 0.8624 - val_loss: 0.2942 - val_acc: 0.8732\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 312s 10ms/step - loss: 0.3116 - acc: 0.8651 - val_loss: 0.3012 - val_acc: 0.8707\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 313s 10ms/step - loss: 0.3067 - acc: 0.8678 - val_loss: 0.2974 - val_acc: 0.8755\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 309s 10ms/step - loss: 0.3020 - acc: 0.8700 - val_loss: 0.3257 - val_acc: 0.8553\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 314s 10ms/step - loss: 0.2970 - acc: 0.8739 - val_loss: 0.2986 - val_acc: 0.8722\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 311s 10ms/step - loss: 0.2922 - acc: 0.8746 - val_loss: 0.2940 - val_acc: 0.8745\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 311s 10ms/step - loss: 0.2890 - acc: 0.8771 - val_loss: 0.2863 - val_acc: 0.8794\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 310s 10ms/step - loss: 0.2827 - acc: 0.8777 - val_loss: 0.2778 - val_acc: 0.8853\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "30000/30000 [==============================] - 308s 10ms/step - loss: 0.2793 - acc: 0.8806 - val_loss: 0.2777 - val_acc: 0.8836\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 307s 10ms/step - loss: 0.2679 - acc: 0.8868 - val_loss: 0.2717 - val_acc: 0.8868\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 310s 10ms/step - loss: 0.2690 - acc: 0.8868 - val_loss: 0.2700 - val_acc: 0.8887\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 311s 10ms/step - loss: 0.2664 - acc: 0.8872 - val_loss: 0.2689 - val_acc: 0.8893\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 309s 10ms/step - loss: 0.2634 - acc: 0.8882 - val_loss: 0.2685 - val_acc: 0.8889\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 312s 10ms/step - loss: 0.2658 - acc: 0.8866 - val_loss: 0.2682 - val_acc: 0.8889\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 316s 11ms/step - loss: 0.2639 - acc: 0.8896 - val_loss: 0.2681 - val_acc: 0.8878\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 320s 11ms/step - loss: 0.2621 - acc: 0.8894 - val_loss: 0.2669 - val_acc: 0.8887\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 320s 11ms/step - loss: 0.2632 - acc: 0.8897 - val_loss: 0.2665 - val_acc: 0.8891\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 322s 11ms/step - loss: 0.2620 - acc: 0.8896 - val_loss: 0.2683 - val_acc: 0.8882\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 315s 10ms/step - loss: 0.2619 - acc: 0.8886 - val_loss: 0.2678 - val_acc: 0.8887\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 311s 10ms/step - loss: 0.2616 - acc: 0.8899 - val_loss: 0.2650 - val_acc: 0.8889\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 308s 10ms/step - loss: 0.2647 - acc: 0.8882 - val_loss: 0.2655 - val_acc: 0.8893\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 317s 11ms/step - loss: 0.2622 - acc: 0.8903 - val_loss: 0.2663 - val_acc: 0.8893\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 316s 11ms/step - loss: 0.2591 - acc: 0.8914 - val_loss: 0.2655 - val_acc: 0.8897\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "30000/30000 [==============================] - 316s 11ms/step - loss: 0.2570 - acc: 0.8897 - val_loss: 0.2650 - val_acc: 0.8901\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 1.0000000474974514e-05.\n",
            "30000/30000 [==============================] - 316s 11ms/step - loss: 0.2559 - acc: 0.8917 - val_loss: 0.2648 - val_acc: 0.8901\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 316s 11ms/step - loss: 0.2565 - acc: 0.8916 - val_loss: 0.2646 - val_acc: 0.8897\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 317s 11ms/step - loss: 0.2580 - acc: 0.8922 - val_loss: 0.2646 - val_acc: 0.8903\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 314s 10ms/step - loss: 0.2572 - acc: 0.8909 - val_loss: 0.2644 - val_acc: 0.8901\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 313s 10ms/step - loss: 0.2588 - acc: 0.8899 - val_loss: 0.2641 - val_acc: 0.8897\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 312s 10ms/step - loss: 0.2598 - acc: 0.8905 - val_loss: 0.2643 - val_acc: 0.8901\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 317s 11ms/step - loss: 0.2581 - acc: 0.8905 - val_loss: 0.2644 - val_acc: 0.8897\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 314s 10ms/step - loss: 0.2563 - acc: 0.8915 - val_loss: 0.2642 - val_acc: 0.8897\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 318s 11ms/step - loss: 0.2575 - acc: 0.8910 - val_loss: 0.2642 - val_acc: 0.8893\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 1.0000000656873453e-05.\n",
            "30000/30000 [==============================] - 320s 11ms/step - loss: 0.2559 - acc: 0.8916 - val_loss: 0.2643 - val_acc: 0.8899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xjml_9LJDV-_",
        "colab_type": "code",
        "outputId": "eebfc6e2-55f8-4d7d-d11e-0a3debb8b02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Get advanced metrics\n",
        "preds = model2.predict(shuffled_data[0:5000])\n",
        "met = perfeval(preds, shuffled_labels[0:5000], 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE: 0.876 SP: 0.901 F-Score: 0.883 PPV: 0.891 gmean: 0.888 AUROC: 0.959 AUPR: 0.958\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}