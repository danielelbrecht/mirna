{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mirna_model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielelbrecht/mirna/blob/master/mirna_model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6BeQMA6f3lht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b090e7a1-d41d-4ce2-a694-b06a4dc41f62"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, TimeDistributed, Dropout, Dense, Permute, Flatten, Multiply, RepeatVector, Activation, Masking\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.wrappers import Wrapper\n",
        "from keras.engine.topology import InputSpec\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HS9wM9vy3vH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data sets\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "pos_file_obj = drive.CreateFile({'id': '1vl-qE0U5W6ll3JH41QqDajyx6oAwC3C0'})                       \n",
        "pos_file_obj.GetContentFile('input.txt')\n",
        "\n",
        "neg_file_obj = drive.CreateFile({'id': '1Rnh8RHUsmCGmiCZobu3g7ezeUJQq0CH-'})                       \n",
        "neg_file_obj.GetContentFile('negatives.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbK21Eqz3yWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_file_obj\n",
        "pos_content = pos_file_obj.GetContentString()\n",
        "neg_content = neg_file_obj.GetContentString()\n",
        "pos_file = []\n",
        "neg_file = []\n",
        "temp = []\n",
        "\n",
        "for x in pos_content:\n",
        "  if x == '\\n':\n",
        "    pos_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "for x in neg_content:\n",
        "  if x == '\\n':\n",
        "    neg_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "    \n",
        "def read_line(line):\n",
        "\n",
        "    array = []\n",
        "\n",
        "    for entry in line:\n",
        "        if entry == '0':\n",
        "            array.append(np.int32(0))\n",
        "        if entry == '1':\n",
        "            array.append(np.int32(1))\n",
        "        if len(array) == 16:\n",
        "          break\n",
        "\n",
        "    return np.asarray(array)\n",
        "  \n",
        "def process_data(pos_file, neg_file):\n",
        "\n",
        "    data = []\n",
        "    is_example = 0\n",
        "    pos_examples = 0\n",
        "    neg_examples = 0\n",
        "\n",
        "    for line in pos_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            pos_examples = pos_examples + 1\n",
        "\n",
        "    for line in neg_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            neg_examples = neg_examples + 1\n",
        "\n",
        "    return np.asarray(data), pos_examples, neg_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Kwf2B_I35Tn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Process the data and generate training labels\n",
        "\n",
        "full_data, num_pos, num_neg = process_data(pos_file, neg_file)\n",
        "\n",
        "# Generate labels\n",
        "pos_labels = np.ones(num_pos)\n",
        "neg_labels = np.zeros(num_neg)\n",
        "data_labels = np.concatenate((pos_labels, neg_labels))\n",
        "\n",
        "binary_labels = np.zeros([len(data_labels), 2])\n",
        "\n",
        "for i in range(len(data_labels)):\n",
        "    if data_labels[i] == 1:\n",
        "        binary_labels[i][1] = 1\n",
        "    else:\n",
        "        binary_labels[i][0] = 1\n",
        "\n",
        "\n",
        "# Get mask length\n",
        "mask_length = 0\n",
        "for i in range(len(full_data)):\n",
        "    if len(full_data[i]) > mask_length:\n",
        "        mask_length = len(full_data[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJ9mekIe38ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5ffc7664-b1eb-4635-f426-84f16a98ffcb"
      },
      "cell_type": "code",
      "source": [
        "# Pad data\n",
        "data_padded = pad_sequences(full_data, maxlen=mask_length, dtype='object', padding='post', truncating='post', value=0)\n",
        "\n",
        "# Shuffle data and get training and validation sets\n",
        "indices = np.random.permutation(35267)\n",
        "shuffled_data = data_padded[indices]\n",
        "shuffled_labels = binary_labels[indices]\n",
        "\n",
        "print(data_padded.shape)\n",
        "print(shuffled_data.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35267, 142, 16)\n",
            "(35267, 142, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8cq6XQao3-1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define hyper parameters\n",
        "LSTM_units = 32\n",
        "fully_connected_layer_units = 32\n",
        "output_size = 2\n",
        "learning_rate = 0.01\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOSR3X7q4BNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "520c0660-036c-4fea-d458-63f603b3fc9f"
      },
      "cell_type": "code",
      "source": [
        "# Functional API model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(mask_length, 16), name='inputs')\n",
        "\n",
        "\n",
        "# LSTM Layers\n",
        "lstm1 = LSTM(20, return_sequences=True, recurrent_dropout=0.1)(inputs)\n",
        "lstm2 = LSTM(10, return_sequences=True, recurrent_dropout=0.1)(lstm1)\n",
        "\n",
        "#Flatten\n",
        "flatten = Flatten()(lstm2)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "do1 = Dropout(0.1)(flatten)\n",
        "fc1 = Dense(200, activation='sigmoid')(do1)\n",
        "do2 = Dropout(0.1)(fc1)\n",
        "fc2 = Dense(100, activation='sigmoid')(do2)\n",
        "\n",
        "# Output layer\n",
        "softmax = Dense(output_size, activation='softmax')(fc2)\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model2 = Model(inputs=inputs, outputs=softmax)\n",
        "\n",
        "model2.compile(optimizer='rmsprop',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 142, 16)           0         \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 142, 20)           2960      \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 142, 10)           1240      \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1420)              0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1420)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 200)               284200    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 308,702\n",
            "Trainable params: 308,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kHwHHSOL6Na-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kfold(k, model, data, labels):\n",
        "  \n",
        "  epochs = 10\n",
        "  length = len(data)\n",
        "  accuracy = 0\n",
        "  model.save_weights('initial_weights')\n",
        "  \n",
        "  for i in range(k):\n",
        "    \n",
        "    model.load_weights('initial_weights')\n",
        "    \n",
        "    #Get validation and training splits from data set\n",
        "    lower_bound = int(i*(length/k))\n",
        "    upper_bound = int((i+1)*(length/k))\n",
        "\n",
        "    train_data = np.concatenate((data[0:lower_bound], data[upper_bound:length]))\n",
        "    val_data = data[lower_bound:upper_bound]\n",
        "    \n",
        "    train_labels = np.concatenate((labels[0:lower_bound], labels[upper_bound:length]))\n",
        "    val_labels = labels[lower_bound:upper_bound]\n",
        "    \n",
        "    history = model.fit(train_data, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,\n",
        "                      batch_size = 128,\n",
        "                      validation_data=(val_data, val_labels))\n",
        "    \n",
        "    accuracy = accuracy + history.history['acc'][epochs-1]\n",
        "    \n",
        "\n",
        "  return accuracy / k\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "An6kLgQB6N95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1819
        },
        "outputId": "0fafe1b3-4f4a-46da-eea6-b563aeed2113"
      },
      "cell_type": "code",
      "source": [
        "# Run 5 fold cross validation\n",
        "kfold_acc = kfold(5, model2, shuffled_data, shuffled_labels)\n",
        "print('5-vold cross validation accuracy is: ', kfold_acc)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.4286 - acc: 0.8039 - val_loss: 0.3561 - val_acc: 0.8456\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3627 - acc: 0.8374 - val_loss: 0.3389 - val_acc: 0.8453\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3467 - acc: 0.8461 - val_loss: 0.3309 - val_acc: 0.8558\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3371 - acc: 0.8481 - val_loss: 0.3265 - val_acc: 0.8558\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3264 - acc: 0.8580 - val_loss: 0.3173 - val_acc: 0.8605\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3204 - acc: 0.8625 - val_loss: 0.3049 - val_acc: 0.8706\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3128 - acc: 0.8629 - val_loss: 0.3029 - val_acc: 0.8674\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.3077 - acc: 0.8683 - val_loss: 0.3118 - val_acc: 0.8680\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 106s 4ms/step - loss: 0.3017 - acc: 0.8702 - val_loss: 0.3037 - val_acc: 0.8680\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.2973 - acc: 0.8723 - val_loss: 0.3218 - val_acc: 0.8548\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.4481 - acc: 0.7899 - val_loss: 0.3953 - val_acc: 0.8206\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3677 - acc: 0.8339 - val_loss: 0.3406 - val_acc: 0.8537\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.3471 - acc: 0.8448 - val_loss: 0.4307 - val_acc: 0.8046\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 105s 4ms/step - loss: 0.3356 - acc: 0.8526 - val_loss: 0.3418 - val_acc: 0.8491\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3273 - acc: 0.8549 - val_loss: 0.3273 - val_acc: 0.8561\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 102s 4ms/step - loss: 0.3219 - acc: 0.8576 - val_loss: 0.3216 - val_acc: 0.8623\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3134 - acc: 0.8635 - val_loss: 0.3095 - val_acc: 0.8666\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3092 - acc: 0.8655 - val_loss: 0.3092 - val_acc: 0.8673\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.3014 - acc: 0.8711 - val_loss: 0.2982 - val_acc: 0.8717\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.2974 - acc: 0.8721 - val_loss: 0.2994 - val_acc: 0.8707\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 105s 4ms/step - loss: 0.4493 - acc: 0.7880 - val_loss: 0.3643 - val_acc: 0.8395\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 102s 4ms/step - loss: 0.3661 - acc: 0.8355 - val_loss: 0.3322 - val_acc: 0.8575\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3489 - acc: 0.8438 - val_loss: 0.3380 - val_acc: 0.8574\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 104s 4ms/step - loss: 0.3376 - acc: 0.8523 - val_loss: 0.3170 - val_acc: 0.8628\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 102s 4ms/step - loss: 0.3280 - acc: 0.8553 - val_loss: 0.3199 - val_acc: 0.8614\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3191 - acc: 0.8590 - val_loss: 0.3000 - val_acc: 0.8718\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 104s 4ms/step - loss: 0.3128 - acc: 0.8635 - val_loss: 0.2929 - val_acc: 0.8777\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3043 - acc: 0.8677 - val_loss: 0.2897 - val_acc: 0.8772\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3008 - acc: 0.8680 - val_loss: 0.3010 - val_acc: 0.8706\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 104s 4ms/step - loss: 0.2959 - acc: 0.8721 - val_loss: 0.2843 - val_acc: 0.8795\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.4471 - acc: 0.7936 - val_loss: 0.3733 - val_acc: 0.8282\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.3622 - acc: 0.8363 - val_loss: 0.3469 - val_acc: 0.8472\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3460 - acc: 0.8467 - val_loss: 0.3432 - val_acc: 0.8493\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 102s 4ms/step - loss: 0.3350 - acc: 0.8528 - val_loss: 0.3476 - val_acc: 0.8426\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3261 - acc: 0.8576 - val_loss: 0.3174 - val_acc: 0.8611\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3170 - acc: 0.8612 - val_loss: 0.3301 - val_acc: 0.8535\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 102s 4ms/step - loss: 0.3101 - acc: 0.8665 - val_loss: 0.3174 - val_acc: 0.8599\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 104s 4ms/step - loss: 0.3051 - acc: 0.8671 - val_loss: 0.3326 - val_acc: 0.8538\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 103s 4ms/step - loss: 0.2989 - acc: 0.8695 - val_loss: 0.3016 - val_acc: 0.8700\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 102s 4ms/step - loss: 0.2959 - acc: 0.8740 - val_loss: 0.3129 - val_acc: 0.8642\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.4484 - acc: 0.7934 - val_loss: 0.3749 - val_acc: 0.8278\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 105s 4ms/step - loss: 0.3647 - acc: 0.8349 - val_loss: 0.3594 - val_acc: 0.8417\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 102s 4ms/step - loss: 0.3468 - acc: 0.8474 - val_loss: 0.3511 - val_acc: 0.8472\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3365 - acc: 0.8522 - val_loss: 0.3305 - val_acc: 0.8500\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3270 - acc: 0.8585 - val_loss: 0.3184 - val_acc: 0.8548\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3166 - acc: 0.8622 - val_loss: 0.3189 - val_acc: 0.8592\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3101 - acc: 0.8673 - val_loss: 0.3177 - val_acc: 0.8601\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.3060 - acc: 0.8687 - val_loss: 0.3143 - val_acc: 0.8633\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 104s 4ms/step - loss: 0.2976 - acc: 0.8732 - val_loss: 0.3146 - val_acc: 0.8638\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 103s 4ms/step - loss: 0.2949 - acc: 0.8745 - val_loss: 0.3168 - val_acc: 0.8623\n",
            "5-vold cross validation accuracy is:  0.8729974240096542\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}