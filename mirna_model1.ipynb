{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mirna_model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielelbrecht/mirna/blob/master/mirna_model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6BeQMA6f3lht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "976f7fcf-5f61-4a70-9075-0f6bcfac61d4"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, TimeDistributed, Dropout, Dense, Permute, Flatten, Multiply, RepeatVector, Activation, Masking, Bidirectional\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.wrappers import Wrapper\n",
        "from keras.engine.topology import InputSpec\n",
        "from keras import backend as K"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HS9wM9vy3vH5",
        "colab_type": "code",
        "outputId": "ae7b6892-b7bd-461d-a174-101e30b83d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Load data sets\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "pos_file_obj = drive.CreateFile({'id': '1vl-qE0U5W6ll3JH41QqDajyx6oAwC3C0'})                       \n",
        "pos_file_obj.GetContentFile('input.txt')\n",
        "\n",
        "neg_file_obj = drive.CreateFile({'id': '1Rnh8RHUsmCGmiCZobu3g7ezeUJQq0CH-'})                       \n",
        "neg_file_obj.GetContentFile('negatives.txt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 27.6MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.1MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.0MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.5MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.0MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.4MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.9MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.4MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.3MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.8MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.8MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.0MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.0MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.0MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.0MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.1MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.1MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 45.1MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.0MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.0MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.1MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.0MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.1MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 9.9MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.0MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.0MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.0MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.3MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 55.9MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 56.9MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 59.2MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 54.6MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 53.1MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 61.0MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 61.3MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 61.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 11.5MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 11.4MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 11.4MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 11.4MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 11.4MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 11.5MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 11.6MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 11.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 11.5MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 11.5MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 61.9MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 61.5MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 63.1MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 63.1MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 10.4MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 10.5MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 10.4MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 10.4MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 10.4MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 10.4MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 10.4MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 10.5MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 10.5MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 10.5MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 64.3MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 64.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 51.8MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 52.4MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 53.4MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 54.1MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 54.0MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 54.6MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 55.3MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 55.0MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 55.8MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 57.6MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 75.8MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 76.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 75.5MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 75.3MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 75.0MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 74.0MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 74.6MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 73.8MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 73.4MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 65.6MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 65.9MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 67.3MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 68.4MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 67.5MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 67.6MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 67.9MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 68.0MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 69.4MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 69.2MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 79.0MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 80.2MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 77.0MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 23.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jbK21Eqz3yWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_file_obj\n",
        "pos_content = pos_file_obj.GetContentString()\n",
        "neg_content = neg_file_obj.GetContentString()\n",
        "pos_file = []\n",
        "neg_file = []\n",
        "temp = []\n",
        "\n",
        "for x in pos_content:\n",
        "  if x == '\\n':\n",
        "    pos_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "for x in neg_content:\n",
        "  if x == '\\n':\n",
        "    neg_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "    \n",
        "def read_line(line):\n",
        "\n",
        "    array = []\n",
        "\n",
        "    for entry in line:\n",
        "        if entry == '0':\n",
        "            array.append(np.int32(0))\n",
        "        if entry == '1':\n",
        "            array.append(np.int32(1))\n",
        "        if len(array) == 16:\n",
        "          break\n",
        "\n",
        "    return np.asarray(array)\n",
        "  \n",
        "def process_data(pos_file, neg_file):\n",
        "\n",
        "    data = []\n",
        "    is_example = 0\n",
        "    pos_examples = 0\n",
        "    neg_examples = 0\n",
        "\n",
        "    for line in pos_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            pos_examples = pos_examples + 1\n",
        "\n",
        "    for line in neg_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            neg_examples = neg_examples + 1\n",
        "\n",
        "    return np.asarray(data), pos_examples, neg_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Kwf2B_I35Tn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Process the data and generate training labels\n",
        "\n",
        "full_data, num_pos, num_neg = process_data(pos_file, neg_file)\n",
        "\n",
        "# Generate labels\n",
        "pos_labels = np.ones(num_pos)\n",
        "neg_labels = np.zeros(num_neg)\n",
        "data_labels = np.concatenate((pos_labels, neg_labels))\n",
        "\n",
        "binary_labels = np.zeros([len(data_labels), 2])\n",
        "\n",
        "for i in range(len(data_labels)):\n",
        "    if data_labels[i] == 1:\n",
        "        binary_labels[i][1] = 1\n",
        "    else:\n",
        "        binary_labels[i][0] = 1\n",
        "\n",
        "\n",
        "# Get mask length\n",
        "mask_length = 0\n",
        "for i in range(len(full_data)):\n",
        "    if len(full_data[i]) > mask_length:\n",
        "        mask_length = len(full_data[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJ9mekIe38ZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pad data\n",
        "data_padded = pad_sequences(full_data, maxlen=mask_length, dtype='object', padding='post', truncating='post', value=0)\n",
        "\n",
        "# Shuffle data and get training and validation sets\n",
        "indices = np.random.permutation(35267)\n",
        "shuffled_data = data_padded[indices]\n",
        "shuffled_labels = binary_labels[indices]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cq6XQao3-1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define hyper parameters\n",
        "LSTM1_units = 32\n",
        "LSTM2_units = 16\n",
        "fully_connected_layer1_units = 32\n",
        "fully_connected_layer2_units = 32\n",
        "output_size = 2\n",
        "learning_rate = 0.01\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOSR3X7q4BNe",
        "colab_type": "code",
        "outputId": "3d408bad-cd4a-47a1-9a46-8708de19a1dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "# Functional API model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(mask_length, 16), name='inputs')\n",
        "\n",
        "\n",
        "# LSTM Layers\n",
        "lstm1 = LSTM(20, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(inputs)\n",
        "lstm2 = LSTM(10, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(lstm1)\n",
        "\n",
        "#Flatten\n",
        "flatten = Flatten()(lstm2)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "do1 = Dropout(0.1)(flatten)\n",
        "fc1 = Dense(200, activation='sigmoid')(do1)\n",
        "do2 = Dropout(0.1)(fc1)\n",
        "fc2 = Dense(100, activation='sigmoid')(do2)\n",
        "\n",
        "# Output layer\n",
        "softmax = Dense(output_size, activation='softmax')(fc2)\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model2 = Model(inputs=inputs, outputs=softmax)\n",
        "\n",
        "model2.compile(optimizer='rmsprop',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 142, 16)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 142, 20)           2960      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 142, 10)           1240      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1420)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1420)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200)               284200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 308,702\n",
            "Trainable params: 308,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-OFwAVVrfoh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kfold(k, model, data, labels):\n",
        "  \n",
        "  epochs = 10\n",
        "  length = len(data)\n",
        "  accuracy = 0\n",
        "  model.save_weights('initial_weights')\n",
        "  \n",
        "  for i in range(k):\n",
        "    \n",
        "    model.load_weights('initial_weights')\n",
        "    \n",
        "    #Get validation and training splits from data set\n",
        "    lower_bound = int(i*(length/k))\n",
        "    upper_bound = int((i+1)*(length/k))\n",
        "\n",
        "    train_data = np.concatenate((data[0:lower_bound], data[upper_bound:length]))\n",
        "    val_data = data[lower_bound:upper_bound]\n",
        "    \n",
        "    train_labels = np.concatenate((labels[0:lower_bound], labels[upper_bound:length]))\n",
        "    val_labels = labels[lower_bound:upper_bound]\n",
        "    \n",
        "    history = model.fit(train_data, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,\n",
        "                      batch_size = 128,\n",
        "                      validation_data=(val_data, val_labels))\n",
        "    \n",
        "    accuracy = accuracy + history.history['acc'][epochs-1]\n",
        "    \n",
        "\n",
        "  return accuracy / k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acTEHWmErgSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1890
        },
        "outputId": "9b237e54-bfeb-4834-93f3-8cab0a5d41a9"
      },
      "cell_type": "code",
      "source": [
        "kfold_acc = kfold(5, model2, shuffled_data, shuffled_labels)\n",
        "print('5-vold cross validation accuracy is: ', kfold_acc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 114s 4ms/step - loss: 0.4548 - acc: 0.7902 - val_loss: 0.3843 - val_acc: 0.8232\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 110s 4ms/step - loss: 0.3916 - acc: 0.8219 - val_loss: 0.3666 - val_acc: 0.8398\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3704 - acc: 0.8337 - val_loss: 0.3575 - val_acc: 0.8422\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3608 - acc: 0.8387 - val_loss: 0.3415 - val_acc: 0.8487\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3520 - acc: 0.8431 - val_loss: 0.3380 - val_acc: 0.8569\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3468 - acc: 0.8468 - val_loss: 0.3191 - val_acc: 0.8596\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 110s 4ms/step - loss: 0.3369 - acc: 0.8518 - val_loss: 0.3319 - val_acc: 0.8574\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 113s 4ms/step - loss: 0.3335 - acc: 0.8542 - val_loss: 0.3143 - val_acc: 0.8664\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 113s 4ms/step - loss: 0.3278 - acc: 0.8560 - val_loss: 0.3095 - val_acc: 0.8660\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3257 - acc: 0.8583 - val_loss: 0.3155 - val_acc: 0.8645\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 115s 4ms/step - loss: 0.4716 - acc: 0.7735 - val_loss: 0.4104 - val_acc: 0.8094\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3893 - acc: 0.8230 - val_loss: 0.3511 - val_acc: 0.8474\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3715 - acc: 0.8314 - val_loss: 0.3365 - val_acc: 0.8520\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3581 - acc: 0.8381 - val_loss: 0.3324 - val_acc: 0.8555\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3514 - acc: 0.8418 - val_loss: 0.3476 - val_acc: 0.8455\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3458 - acc: 0.8478 - val_loss: 0.3165 - val_acc: 0.8622\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3384 - acc: 0.8481 - val_loss: 0.3167 - val_acc: 0.8639\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3351 - acc: 0.8518 - val_loss: 0.3225 - val_acc: 0.8633\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3340 - acc: 0.8518 - val_loss: 0.3171 - val_acc: 0.8637\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 110s 4ms/step - loss: 0.3242 - acc: 0.8580 - val_loss: 0.3014 - val_acc: 0.8728\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.4713 - acc: 0.7772 - val_loss: 0.4021 - val_acc: 0.8062\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3899 - acc: 0.8226 - val_loss: 0.3601 - val_acc: 0.8313\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3694 - acc: 0.8336 - val_loss: 0.3507 - val_acc: 0.8377\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.3589 - acc: 0.8403 - val_loss: 0.3426 - val_acc: 0.8458\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 113s 4ms/step - loss: 0.3539 - acc: 0.8436 - val_loss: 0.3251 - val_acc: 0.8544\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.3419 - acc: 0.8499 - val_loss: 0.3207 - val_acc: 0.8575\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.3408 - acc: 0.8476 - val_loss: 0.3191 - val_acc: 0.8615\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 112s 4ms/step - loss: 0.3324 - acc: 0.8530 - val_loss: 0.3258 - val_acc: 0.8587\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 112s 4ms/step - loss: 0.3274 - acc: 0.8566 - val_loss: 0.3172 - val_acc: 0.8605\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3282 - acc: 0.8563 - val_loss: 0.3146 - val_acc: 0.8606\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.4734 - acc: 0.7760 - val_loss: 0.3990 - val_acc: 0.8109\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3954 - acc: 0.8186 - val_loss: 0.3427 - val_acc: 0.8567\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3734 - acc: 0.8293 - val_loss: 0.3335 - val_acc: 0.8565\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3626 - acc: 0.8372 - val_loss: 0.3277 - val_acc: 0.8558\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 109s 4ms/step - loss: 0.3534 - acc: 0.8424 - val_loss: 0.3122 - val_acc: 0.8680\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 112s 4ms/step - loss: 0.3473 - acc: 0.8459 - val_loss: 0.3114 - val_acc: 0.8681\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3403 - acc: 0.8502 - val_loss: 0.3027 - val_acc: 0.8693\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3362 - acc: 0.8493 - val_loss: 0.3122 - val_acc: 0.8662\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 111s 4ms/step - loss: 0.3289 - acc: 0.8562 - val_loss: 0.3129 - val_acc: 0.8635\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 110s 4ms/step - loss: 0.3274 - acc: 0.8559 - val_loss: 0.2906 - val_acc: 0.8772\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 109s 4ms/step - loss: 0.4731 - acc: 0.7774 - val_loss: 0.3761 - val_acc: 0.8266\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.3901 - acc: 0.8204 - val_loss: 0.3476 - val_acc: 0.8422\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3693 - acc: 0.8330 - val_loss: 0.3329 - val_acc: 0.8540\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3591 - acc: 0.8391 - val_loss: 0.3237 - val_acc: 0.8621\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 114s 4ms/step - loss: 0.3527 - acc: 0.8422 - val_loss: 0.3243 - val_acc: 0.8598\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3443 - acc: 0.8472 - val_loss: 0.3249 - val_acc: 0.8580\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.3403 - acc: 0.8502 - val_loss: 0.3300 - val_acc: 0.8588\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 111s 4ms/step - loss: 0.3352 - acc: 0.8519 - val_loss: 0.3122 - val_acc: 0.8676\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 110s 4ms/step - loss: 0.3277 - acc: 0.8574 - val_loss: 0.3320 - val_acc: 0.8544\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 114s 4ms/step - loss: 0.3270 - acc: 0.8564 - val_loss: 0.3100 - val_acc: 0.8656\n",
            "5-vold cross validation accuracy is:  0.856976768944181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXWVgtQQrkHb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def perfeval(predictions, Y_test, verbose=0):\n",
        " class_label = np.uint8(np.argmax(predictions,axis=1))\n",
        " R = np.asarray(np.uint8([sublist[1] for sublist in Y_test]))\n",
        " CM = metrics.confusion_matrix(R, class_label, labels=None)\n",
        " \n",
        " CM = np.double(CM)\n",
        " acc = (CM[0][0]+CM[1][1])/(CM[0][0]+CM[0][1]+CM[1][0]+CM[1][1])\n",
        " se = (CM[0][0])/(CM[0][0]+CM[0][1])\n",
        " sp = (CM[1][1])/(CM[1][0]+CM[1][1])\n",
        " f1 = (2*CM[0][0])/(2*CM[0][0]+CM[0][1]+CM[1][0])\n",
        " ppv = (CM[0][0])/(CM[0][0]+CM[1][0])\n",
        " mcc = (CM[0][0]*CM[1][1]-CM[0][1]*CM[1][0])/np.sqrt((CM[0][0]+CM[0][1])*(CM[0][0]+CM[1][0])*(CM[0][1]+CM[1][1])*(CM[1][0]+CM[1][1]))\n",
        " gmean = np.sqrt(se*sp)\n",
        " auroc = metrics.roc_auc_score(Y_test[:,0],predictions[:,0])\n",
        " aupr = metrics.average_precision_score(Y_test[:,0],predictions[:,0],average=\"micro\")\n",
        "  \n",
        " if verbose == 1:\n",
        "  print(\"SE:\",\"{:.3f}\".format(se),\"SP:\",\"{:.3f}\".format(sp),\"F-Score:\",\"{:.3f}\".format(f1), \"PPV:\",\"{:.3f}\".format(ppv),\"gmean:\",\"{:.3f}\".format(gmean),\"AUROC:\",\"{:.3f}\".format(auroc), \"AUPR:\",\"{:.3f}\".format(aupr))\n",
        " \n",
        " return [se,sp,f1,ppv,gmean,auroc,aupr,CM]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SzZdKX5rqyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5647a368-73a1-4458-e294-9eecd5a983ca"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Get advanced metrics\n",
        "preds = model2.predict(shuffled_data[0:5000])\n",
        "met = perfeval(preds, shuffled_labels[0:5000], 1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE: 0.889 SP: 0.862 F-Score: 0.872 PPV: 0.855 gmean: 0.875 AUROC: 0.948 AUPR: 0.946\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}