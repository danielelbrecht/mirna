{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mirna_model2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielelbrecht/mirna/blob/master/mirna_model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6BeQMA6f3lht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, TimeDistributed, Dropout, Dense, Permute, Flatten, Multiply, RepeatVector, Activation, Masking, Bidirectional\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.wrappers import Wrapper\n",
        "from keras.engine.topology import InputSpec\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HS9wM9vy3vH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data sets\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "pos_file_obj = drive.CreateFile({'id': '1vl-qE0U5W6ll3JH41QqDajyx6oAwC3C0'})                       \n",
        "pos_file_obj.GetContentFile('input.txt')\n",
        "\n",
        "neg_file_obj = drive.CreateFile({'id': '1Rnh8RHUsmCGmiCZobu3g7ezeUJQq0CH-'})                       \n",
        "neg_file_obj.GetContentFile('negatives.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbK21Eqz3yWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_file_obj\n",
        "pos_content = pos_file_obj.GetContentString()\n",
        "neg_content = neg_file_obj.GetContentString()\n",
        "pos_file = []\n",
        "neg_file = []\n",
        "temp = []\n",
        "\n",
        "for x in pos_content:\n",
        "  if x == '\\n':\n",
        "    pos_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "for x in neg_content:\n",
        "  if x == '\\n':\n",
        "    neg_file.append(temp)\n",
        "    temp = []\n",
        "  else: \n",
        "    temp.append(x)\n",
        "    \n",
        "    \n",
        "def read_line(line):\n",
        "\n",
        "    array = []\n",
        "\n",
        "    for entry in line:\n",
        "        if entry == '0':\n",
        "            array.append(np.int32(0))\n",
        "        if entry == '1':\n",
        "            array.append(np.int32(1))\n",
        "        if len(array) == 16:\n",
        "          break\n",
        "\n",
        "    return np.asarray(array)\n",
        "  \n",
        "def process_data(pos_file, neg_file):\n",
        "\n",
        "    data = []\n",
        "    is_example = 0\n",
        "    pos_examples = 0\n",
        "    neg_examples = 0\n",
        "\n",
        "    for line in pos_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            pos_examples = pos_examples + 1\n",
        "\n",
        "    for line in neg_file: # Iterate over file\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 0:  # When new sequence is encountered, initialize new example\n",
        "            example = []\n",
        "            is_example = 1\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if (line[0] == '0' or line[0] == '1') and is_example == 1:  # During sequence\n",
        "            example.append(read_line(line))\n",
        "\n",
        "        if line[0] != '0' and line[0] != '1' and is_example == 1:  # When sequence terminates\n",
        "            is_example = 0\n",
        "            data.append(example)\n",
        "            neg_examples = neg_examples + 1\n",
        "\n",
        "    return np.asarray(data), pos_examples, neg_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Kwf2B_I35Tn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Process the data and generate training labels\n",
        "\n",
        "full_data, num_pos, num_neg = process_data(pos_file, neg_file)\n",
        "\n",
        "# Generate labels\n",
        "pos_labels = np.ones(num_pos)\n",
        "neg_labels = np.zeros(num_neg)\n",
        "data_labels = np.concatenate((pos_labels, neg_labels))\n",
        "\n",
        "binary_labels = np.zeros([len(data_labels), 2])\n",
        "\n",
        "for i in range(len(data_labels)):\n",
        "    if data_labels[i] == 1:\n",
        "        binary_labels[i][1] = 1\n",
        "    else:\n",
        "        binary_labels[i][0] = 1\n",
        "\n",
        "\n",
        "# Get mask length\n",
        "mask_length = 0\n",
        "for i in range(len(full_data)):\n",
        "    if len(full_data[i]) > mask_length:\n",
        "        mask_length = len(full_data[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJ9mekIe38ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5ffc7664-b1eb-4635-f426-84f16a98ffcb"
      },
      "cell_type": "code",
      "source": [
        "# Pad data\n",
        "data_padded = pad_sequences(full_data, maxlen=mask_length, dtype='object', padding='post', truncating='post', value=0)\n",
        "\n",
        "# Shuffle data and get training and validation sets\n",
        "indices = np.random.permutation(35267)\n",
        "shuffled_data = data_padded[indices]\n",
        "shuffled_labels = binary_labels[indices]\n",
        "\n",
        "print(data_padded.shape)\n",
        "print(shuffled_data.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35267, 142, 16)\n",
            "(35267, 142, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8cq6XQao3-1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define hyper parameters\n",
        "LSTM_units = 32\n",
        "fully_connected_layer_units = 32\n",
        "output_size = 2\n",
        "learning_rate = 0.01\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOSR3X7q4BNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "3e7fbe11-5dbd-45c2-f52f-7e87c9c1e286"
      },
      "cell_type": "code",
      "source": [
        "# Functional API model\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(mask_length, 16), name='inputs')\n",
        "\n",
        "\n",
        "# LSTM Layers\n",
        "lstm1 = Bidirectional(LSTM(20, return_sequences=True, recurrent_dropout=0.1), merge_mode='concat')(inputs)\n",
        "lstm2 = Bidirectional(LSTM(10, return_sequences=True, recurrent_dropout=0.1), merge_mode='concat')(lstm1)\n",
        "\n",
        "#Flatten\n",
        "flatten = Flatten()(lstm2)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "do1 = Dropout(0.1)(flatten)\n",
        "fc1 = Dense(100, activation='sigmoid')(do1)\n",
        "do2 = Dropout(0.1)(fc1)\n",
        "fc2 = Dense(100, activation='sigmoid')(do2)\n",
        "\n",
        "# Output layer\n",
        "softmax = Dense(output_size, activation='softmax')(fc2)\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model2 = Model(inputs=inputs, outputs=softmax)\n",
        "\n",
        "model2.compile(optimizer='rmsprop',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 142, 16)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 142, 40)           5920      \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 142, 20)           4080      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 2840)              0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 2840)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 100)               284100    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 304,402\n",
            "Trainable params: 304,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kHwHHSOL6Na-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def kfold(k, model, data, labels):\n",
        "  \n",
        "  epochs = 10\n",
        "  length = len(data)\n",
        "  accuracy = 0\n",
        "  model.save_weights('initial_weights')\n",
        "  \n",
        "  for i in range(k):\n",
        "    \n",
        "    model.load_weights('initial_weights')\n",
        "    \n",
        "    #Get validation and training splits from data set\n",
        "    lower_bound = int(i*(length/k))\n",
        "    upper_bound = int((i+1)*(length/k))\n",
        "\n",
        "    train_data = np.concatenate((data[0:lower_bound], data[upper_bound:length]))\n",
        "    val_data = data[lower_bound:upper_bound]\n",
        "    \n",
        "    train_labels = np.concatenate((labels[0:lower_bound], labels[upper_bound:length]))\n",
        "    val_labels = labels[lower_bound:upper_bound]\n",
        "    \n",
        "    history = model.fit(train_data, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,\n",
        "                      batch_size = 128,\n",
        "                      validation_data=(val_data, val_labels))\n",
        "    \n",
        "    accuracy = accuracy + history.history['acc'][epochs-1]\n",
        "    \n",
        "\n",
        "  return accuracy / k\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "An6kLgQB6N95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1819
        },
        "outputId": "86c05908-5fbc-45b5-b6f2-be96440a3a4b"
      },
      "cell_type": "code",
      "source": [
        "# Run 5 fold cross validation\n",
        "kfold_acc = kfold(5, model2, shuffled_data, shuffled_labels)\n",
        "print('5-vold cross validation accuracy is: ', kfold_acc)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 214s 8ms/step - loss: 0.4147 - acc: 0.8146 - val_loss: 0.3796 - val_acc: 0.8266\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.3510 - acc: 0.8443 - val_loss: 0.3605 - val_acc: 0.8411\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.3331 - acc: 0.8556 - val_loss: 0.3170 - val_acc: 0.8606\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 206s 7ms/step - loss: 0.3214 - acc: 0.8606 - val_loss: 0.3234 - val_acc: 0.8579\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 210s 7ms/step - loss: 0.3126 - acc: 0.8661 - val_loss: 0.3034 - val_acc: 0.8679\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.3061 - acc: 0.8690 - val_loss: 0.2959 - val_acc: 0.8737\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 206s 7ms/step - loss: 0.2984 - acc: 0.8724 - val_loss: 0.3098 - val_acc: 0.8635\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.2950 - acc: 0.8737 - val_loss: 0.2874 - val_acc: 0.8752\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 206s 7ms/step - loss: 0.2873 - acc: 0.8776 - val_loss: 0.2883 - val_acc: 0.8761\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.2836 - acc: 0.8798 - val_loss: 0.2888 - val_acc: 0.8779\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.4350 - acc: 0.7996 - val_loss: 0.3680 - val_acc: 0.8388\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.3539 - acc: 0.8415 - val_loss: 0.3260 - val_acc: 0.8625\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.3320 - acc: 0.8537 - val_loss: 0.3278 - val_acc: 0.8581\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.3197 - acc: 0.8604 - val_loss: 0.3075 - val_acc: 0.8701\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.3117 - acc: 0.8636 - val_loss: 0.3165 - val_acc: 0.8626\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.3044 - acc: 0.8701 - val_loss: 0.3027 - val_acc: 0.8701\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.2980 - acc: 0.8732 - val_loss: 0.3005 - val_acc: 0.8701\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.2910 - acc: 0.8760 - val_loss: 0.2946 - val_acc: 0.8741\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 206s 7ms/step - loss: 0.2866 - acc: 0.8775 - val_loss: 0.2987 - val_acc: 0.8703\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 209s 7ms/step - loss: 0.2817 - acc: 0.8795 - val_loss: 0.3400 - val_acc: 0.8481\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.4468 - acc: 0.7939 - val_loss: 0.3497 - val_acc: 0.8472\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.3548 - acc: 0.8425 - val_loss: 0.3344 - val_acc: 0.8548\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.3342 - acc: 0.8521 - val_loss: 0.3151 - val_acc: 0.8659\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.3235 - acc: 0.8586 - val_loss: 0.3165 - val_acc: 0.8646\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.3150 - acc: 0.8623 - val_loss: 0.2976 - val_acc: 0.8757\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.3073 - acc: 0.8668 - val_loss: 0.2870 - val_acc: 0.8821\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 210s 7ms/step - loss: 0.2984 - acc: 0.8699 - val_loss: 0.3417 - val_acc: 0.8452\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 206s 7ms/step - loss: 0.2946 - acc: 0.8726 - val_loss: 0.2821 - val_acc: 0.8840\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.2880 - acc: 0.8752 - val_loss: 0.2781 - val_acc: 0.8850\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.2822 - acc: 0.8774 - val_loss: 0.2831 - val_acc: 0.8826\n",
            "Train on 28214 samples, validate on 7053 samples\n",
            "Epoch 1/10\n",
            "28214/28214 [==============================] - 205s 7ms/step - loss: 0.4389 - acc: 0.7988 - val_loss: 0.3555 - val_acc: 0.8411\n",
            "Epoch 2/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.3509 - acc: 0.8457 - val_loss: 0.3327 - val_acc: 0.8551\n",
            "Epoch 3/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.3293 - acc: 0.8559 - val_loss: 0.3461 - val_acc: 0.8405\n",
            "Epoch 4/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.3184 - acc: 0.8604 - val_loss: 0.3104 - val_acc: 0.8620\n",
            "Epoch 5/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.3105 - acc: 0.8651 - val_loss: 0.3114 - val_acc: 0.8632\n",
            "Epoch 6/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.3022 - acc: 0.8703 - val_loss: 0.2957 - val_acc: 0.8721\n",
            "Epoch 7/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.2949 - acc: 0.8724 - val_loss: 0.3036 - val_acc: 0.8667\n",
            "Epoch 8/10\n",
            "28214/28214 [==============================] - 208s 7ms/step - loss: 0.2902 - acc: 0.8752 - val_loss: 0.2993 - val_acc: 0.8689\n",
            "Epoch 9/10\n",
            "28214/28214 [==============================] - 207s 7ms/step - loss: 0.2840 - acc: 0.8779 - val_loss: 0.2972 - val_acc: 0.8691\n",
            "Epoch 10/10\n",
            "28214/28214 [==============================] - 205s 7ms/step - loss: 0.2799 - acc: 0.8816 - val_loss: 0.2863 - val_acc: 0.8762\n",
            "Train on 28213 samples, validate on 7054 samples\n",
            "Epoch 1/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.4402 - acc: 0.7965 - val_loss: 0.4189 - val_acc: 0.8051\n",
            "Epoch 2/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.3508 - acc: 0.8466 - val_loss: 0.3680 - val_acc: 0.8326\n",
            "Epoch 3/10\n",
            "28213/28213 [==============================] - 205s 7ms/step - loss: 0.3302 - acc: 0.8568 - val_loss: 0.3282 - val_acc: 0.8513\n",
            "Epoch 4/10\n",
            "28213/28213 [==============================] - 209s 7ms/step - loss: 0.3207 - acc: 0.8626 - val_loss: 0.3102 - val_acc: 0.8589\n",
            "Epoch 5/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.3105 - acc: 0.8659 - val_loss: 0.3043 - val_acc: 0.8626\n",
            "Epoch 6/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.3021 - acc: 0.8701 - val_loss: 0.3045 - val_acc: 0.8653\n",
            "Epoch 7/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.2952 - acc: 0.8750 - val_loss: 0.3343 - val_acc: 0.8531\n",
            "Epoch 8/10\n",
            "28213/28213 [==============================] - 208s 7ms/step - loss: 0.2904 - acc: 0.8755 - val_loss: 0.3100 - val_acc: 0.8628\n",
            "Epoch 9/10\n",
            "28213/28213 [==============================] - 206s 7ms/step - loss: 0.2852 - acc: 0.8786 - val_loss: 0.2856 - val_acc: 0.8709\n",
            "Epoch 10/10\n",
            "28213/28213 [==============================] - 207s 7ms/step - loss: 0.2787 - acc: 0.8818 - val_loss: 0.2892 - val_acc: 0.8720\n",
            "5-vold cross validation accuracy is:  0.8800223942200892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ut3LCvWfDT8M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def perfeval(predictions, Y_test, verbose=0):\n",
        " class_label = np.uint8(np.argmax(predictions,axis=1))\n",
        " R = np.asarray(np.uint8([sublist[1] for sublist in Y_test]))\n",
        " CM = metrics.confusion_matrix(R, class_label, labels=None)\n",
        " \n",
        " CM = np.double(CM)\n",
        " acc = (CM[0][0]+CM[1][1])/(CM[0][0]+CM[0][1]+CM[1][0]+CM[1][1])\n",
        " se = (CM[0][0])/(CM[0][0]+CM[0][1])\n",
        " sp = (CM[1][1])/(CM[1][0]+CM[1][1])\n",
        " f1 = (2*CM[0][0])/(2*CM[0][0]+CM[0][1]+CM[1][0])\n",
        " ppv = (CM[0][0])/(CM[0][0]+CM[1][0])\n",
        " mcc = (CM[0][0]*CM[1][1]-CM[0][1]*CM[1][0])/np.sqrt((CM[0][0]+CM[0][1])*(CM[0][0]+CM[1][0])*(CM[0][1]+CM[1][1])*(CM[1][0]+CM[1][1]))\n",
        " gmean = np.sqrt(se*sp)\n",
        " auroc = metrics.roc_auc_score(Y_test[:,0],predictions[:,0])\n",
        " aupr = metrics.average_precision_score(Y_test[:,0],predictions[:,0],average=\"micro\")\n",
        "  \n",
        " if verbose == 1:\n",
        "  print(\"SE:\",\"{:.3f}\".format(se),\"SP:\",\"{:.3f}\".format(sp),\"F-Score:\",\"{:.3f}\".format(f1), \"PPV:\",\"{:.3f}\".format(ppv),\"gmean:\",\"{:.3f}\".format(gmean),\"AUROC:\",\"{:.3f}\".format(auroc), \"AUPR:\",\"{:.3f}\".format(aupr))\n",
        " \n",
        " return [se,sp,f1,ppv,gmean,auroc,aupr,CM]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xjml_9LJDV-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eebfc6e2-55f8-4d7d-d11e-0a3debb8b02d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Get advanced metrics\n",
        "preds = model2.predict(shuffled_data[0:5000])\n",
        "met = perfeval(preds, shuffled_labels[0:5000], 1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE: 0.876 SP: 0.901 F-Score: 0.883 PPV: 0.891 gmean: 0.888 AUROC: 0.959 AUPR: 0.958\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}